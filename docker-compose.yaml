services:
  llm-server:
    build:
      context: ./llm-server
    container_name: llm_server
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu] # GPU 사용을 위한 설정
    volumes:
      - ./llm-server:/app
    runtime: nvidia

  client-app:
    build:
      context: ./client-app
    container_name: client_app
    depends_on:
      - llm-server
    volumes:
      - ./client-app:/app

    environment:
      - LLM_SERVER_URL=http://llm-server:8000 # 서버 URL을 환경 변수로 설정

